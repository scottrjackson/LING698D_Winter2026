---
title: "LING698D: Hierarchical modeling"
subtitle: "Day 4"
author: "Scott Jackson"
date: "2026-01-16"
---

# Agenda

1. Questions, review, problems
2. Exploring Practice data

# Questions

- 

# Loading libraries

```{r}
library(tidyverse)
library(lme4)
library(lmerTest)

```

# Practicing with real data: McGowan et al. (2026)

- Copy of Cognition paper loaded on ELMS
- All data and sample code from here: https://osf.io/xej9k/files/osfstorage
- Disclaimer: I am not attempting to criticize or endorse the paper; we are just using this as fodder for practice and illustration exercises.


## Loading the data and renaming columns
```{r}
mcgowan <- read_csv("practice_data/Combined exp 2 - dataset - 248 participants.csv")
colnames(mcgowan)
mcgowan <- rename(mcgowan,
                  subject = Participant_ID,
                  sentence = Sentence_Type,
                  exp = Experiment,
                  loc = Location,
                  trial = Trial_Number,
                  RT = Reaction_Time,
                  ACC = Accuracy,
                  rate = Presentation_Rate)
colnames(mcgowan)
head(mcgowan)
```

## Some exploratory data analysis

- histograms!
- consider transformations
- create subsets

```{r}
ggplot(mcgowan, aes(RT)) + geom_histogram()
ggplot(mcgowan, aes(log(RT))) + geom_histogram()

range(mcgowan$RT)
mean_RT <- mean(mcgowan$RT)
sd_RT <- sd(mcgowan$RT)

mean_RT - 2.5*sd_RT

mean(mcgowan$RT > 20000)
quantile(mcgowan$RT, .0002)

mcgowan <- filter(mcgowan, RT >= 10, RT <= 20000)

ggplot(mcgowan, aes(log(RT))) + geom_histogram()
ggplot(mcgowan, aes(RT)) + geom_histogram() +
  xlim(0, 5000)

```

# General Model Building Advice

- **Remember**:
  - Binary thinking is dangerous (i.e., thinking an effect is "real" or not)
  - Focus on **estimates** and **uncertainty**
  - It's okay to say "we can't conclude X from this data"!

- Two *complementary* approaches (do both!):
  1. **Explore** by starting simple, building up
  2. **Draw inferences** with the most complex, *reasonable* model possible

- Model comparison statistics/procedures:
  1. **AIC** is a good general-purpose tool for comparing a "penalized" fit
    - based on likelihood
    - does not always prefer more complex models (like R^2 does)
    - can *only* compare models with **identical** y values (thing you're predicting)
    - **can** compare models with completely different sets of predictors
      - (in other words: the *left* side of the model must be identical, but the *right* sides can be anything)
    - numeric value doesn't indicate "how good" the fit is, just whether it's better than an alternative
    - does not support traditional NHST hypothesis testing
    - good guide for *exploration*, not usually sufficient for *inferences*
  2. **Likelihood ratio tests** (aka LRT, aka "log likelihood test")
    - negative 2 times the difference in log-likelihoods is assumed to have a chi-square distribution
    - can **only** compare a simpler model vs. a more complex model
    - i.e., the more complex model must "contain" the simpler model
    - can be used in a hypothesis-testing framework
      - but the p-values can be off

- Scott's opinions:
  - Using p-values/hypothesis-testing to find the "best" model can be problematic.
  - Start off by building from simpler models to inform your own grasp of your data.
  - Better to use a combination of "top-down" theory and "keep it maximal" within reason if you are hypothesis-testing.
  - Don't be afraid to report a few different model results, as a kind of "sensitivity analysis".

# Building to a mixed-effect model

Some theory/background to discuss:
- Maximum likelihood vs. REML
- BLUPs vs. Estimates

```{r}
colnames(mcgowan)
xtabs(~ sentence, mcgowan)
mcgowan_ungrammatical <- filter(mcgowan, 
                        sentence %in% c("control", "transposed"))

mcgowan_RT <- filter(mcgowan_ungrammatical, ACC == 1)
ggplot(mcgowan_RT, aes(log(RT))) + geom_histogram()

mcgowan_RT$logRT <- log(mcgowan_RT$RT)

rt_lm0 <- lm(logRT ~ 1, mcgowan_RT)
summary(rt_lm0)

ggplot(mcgowan_RT, aes(trial, logRT)) + geom_point(alpha = .01) +
  geom_smooth(method = "lm")

rt_lm1 <- lm(logRT ~ 1 + trial, mcgowan_RT)
summary(rt_lm1)

summary(mcgowan_RT$trial)

exp(6.44 - .0019)

exp(6.44 - .0019*224)

```


```{r}
rt_lm2 <- lm(logRT ~ 1 + trial + subject, mcgowan_RT)
length(unique(mcgowan_RT$subject))
summary(rt_lm2)

rt_lmer2 <- lmer(logRT ~ 1 + trial + (1 | subject), mcgowan_RT)
summary(rt_lmer2)

AIC(rt_lm1)
AIC(rt_lm2)


rt_lmer2_ml <- lmer(logRT ~ 1 + trial + (1 | subject), mcgowan_RT,
                 REML = FALSE)

AIC(rt_lmer2_ml)
head(ranef(rt_lmer2)$subject)

```
